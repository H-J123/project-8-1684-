{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b6ad62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navie Bayes\n",
    "# =====================================================\n",
    "# Naive Bayes with and without LOA Feature Selection\n",
    "# Dataset: KC2\n",
    "# =====================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 1Ô∏è‚É£ Load and Prepare the Dataset\n",
    "# -----------------------------------------------------\n",
    "data = pd.read_csv(r\"/content/KC2_csv.csv\")  # Ensure KC2.csv is in your working directory\n",
    "\n",
    "# Encode any categorical columns\n",
    "for col in data.columns:\n",
    "    if data[col].dtype == 'object':\n",
    "        data[col] = LabelEncoder().fit_transform(data[col])\n",
    "\n",
    "# Split into features and labels\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 2Ô∏è‚É£ Lyrebird Optimization Algorithm (LOA)\n",
    "# -----------------------------------------------------\n",
    "def LOA(num_agents, max_iter, X, y):\n",
    "    num_features = X.shape[1]\n",
    "    population = np.random.randint(0, 2, (num_agents, num_features))\n",
    "    fitness = np.zeros(num_agents)\n",
    "\n",
    "    def fitness_function(solution):\n",
    "        if np.sum(solution) == 0:\n",
    "            return 0\n",
    "        X_sel = X[:, solution == 1]\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_sel, y, test_size=0.3, random_state=42)\n",
    "        model = GaussianNB()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        return accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Initial fitness evaluation\n",
    "    for i in range(num_agents):\n",
    "        fitness[i] = fitness_function(population[i])\n",
    "\n",
    "    best_idx = np.argmax(fitness)\n",
    "    best_solution = population[best_idx].copy()\n",
    "    best_fitness = fitness[best_idx]\n",
    "    convergence_curve = []\n",
    "\n",
    "    # Main LOA loop\n",
    "    for t in range(max_iter):\n",
    "        for i in range(num_agents):\n",
    "            rand1, rand2, rand3, rand4 = np.random.rand(4, num_features)\n",
    "            new_sol = population[i] ^ ((rand1 < 0.5) & (rand2 > 0.5))\n",
    "            new_sol = new_sol ^ ((rand3 > 0.7) | (rand4 < 0.3))\n",
    "            new_sol = new_sol.astype(int)\n",
    "\n",
    "            new_fit = fitness_function(new_sol)\n",
    "            if new_fit > fitness[i]:\n",
    "                population[i] = new_sol\n",
    "                fitness[i] = new_fit\n",
    "\n",
    "        # Update global best\n",
    "        best_idx = np.argmax(fitness)\n",
    "        if fitness[best_idx] > best_fitness:\n",
    "            best_solution = population[best_idx].copy()\n",
    "            best_fitness = fitness[best_idx]\n",
    "\n",
    "        convergence_curve.append(best_fitness)\n",
    "        print(f\"Iteration {t+1}/{max_iter} ‚Üí Best Accuracy: {best_fitness:.4f}\")\n",
    "\n",
    "    return best_solution, best_fitness, convergence_curve\n",
    "\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 3Ô∏è‚É£ Run LOA for Feature Selection\n",
    "# -----------------------------------------------------\n",
    "num_agents = 20\n",
    "max_iter = 30\n",
    "\n",
    "best_features, best_acc, convergence_curve = LOA(num_agents, max_iter, X, y)\n",
    "selected_features = np.where(best_features == 1)[0]\n",
    "\n",
    "print(\"\\n‚úÖ Selected Features Indexes:\", selected_features)\n",
    "print(\"‚úÖ Best Feature Subset Accuracy:\", best_acc)\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 4Ô∏è‚É£ Naive Bayes with LOA Feature Selection\n",
    "# -----------------------------------------------------\n",
    "X_selected = X[:, best_features == 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "acc1 = accuracy_score(y_test, y_pred)\n",
    "prec1 = precision_score(y_test, y_pred)\n",
    "rec1 = recall_score(y_test, y_pred)\n",
    "f11 = f1_score(y_test, y_pred)\n",
    "auc1 = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "print(\"\\n=== ü¶ú Naive Bayes with LOA Feature Selection ===\")\n",
    "print(f\"Accuracy:  {acc1:.4f}\")\n",
    "print(f\"Precision: {prec1:.4f}\")\n",
    "print(f\"Recall:    {rec1:.4f}\")\n",
    "print(f\"F1-Score:  {f11:.4f}\")\n",
    "print(f\"AUC:       {auc1:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 5Ô∏è‚É£ Naive Bayes without Feature Selection (Baseline)\n",
    "# -----------------------------------------------------\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "model2 = GaussianNB()\n",
    "model2.fit(X_train2, y_train2)\n",
    "y_pred2 = model2.predict(X_test2)\n",
    "y_prob2 = model2.predict_proba(X_test2)[:, 1]\n",
    "\n",
    "# Metrics\n",
    "acc2 = accuracy_score(y_test2, y_pred2)\n",
    "prec2 = precision_score(y_test2, y_pred2)\n",
    "rec2 = recall_score(y_test2, y_pred2)\n",
    "f12 = f1_score(y_test2, y_pred2)\n",
    "auc2 = roc_auc_score(y_test2, y_prob2)\n",
    "\n",
    "print(\"\\n=== ‚öôÔ∏è Naive Bayes without Feature Selection ===\")\n",
    "print(f\"Accuracy:  {acc2:.4f}\")\n",
    "print(f\"Precision: {prec2:.4f}\")\n",
    "print(f\"Recall:    {rec2:.4f}\")\n",
    "print(f\"F1-Score:  {f12:.4f}\")\n",
    "print(f\"AUC:       {auc2:.4f}\")\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 6Ô∏è‚É£ Visualization: Convergence + ROC Curves\n",
    "# -----------------------------------------------------\n",
    "\n",
    "# (a) Convergence Curve\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(convergence_curve, 'b-', linewidth=2)\n",
    "plt.title(\"Lyrebird Optimization Algorithm (LOA) Convergence Curve\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# (b) ROC Curves Comparison\n",
    "fpr1, tpr1, _ = roc_curve(y_test, y_prob)\n",
    "fpr2, tpr2, _ = roc_curve(y_test2, y_prob2)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(fpr1, tpr1, 'r-', label=f'With LOA (AUC={auc1:.4f})')\n",
    "plt.plot(fpr2, tpr2, 'b--', label=f'Without LOA (AUC={auc2:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title(\"ROC Curve Comparison - Naive Bayes\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------\n",
    "# 7Ô∏è‚É£ Summary Comparison\n",
    "# -----------------------------------------------------\n",
    "print(\"\\n====================== SUMMARY COMPARISON ======================\")\n",
    "print(f\"{'Metric':<12} | {'With LOA':<10} | {'Without LOA':<10}\")\n",
    "print(\"---------------------------------------------------------------\")\n",
    "print(f\"{'Accuracy':<12} | {acc1:<10.4f} | {acc2:<10.4f}\")\n",
    "print(f\"{'Precision':<12} | {prec1:<10.4f} | {prec2:<10.4f}\")\n",
    "print(f\"{'Recall':<12} | {rec1:<10.4f} | {rec2:<10.4f}\")\n",
    "print(f\"{'F1-Score':<12} | {f11:<10.4f} | {f12:<10.4f}\")\n",
    "print(f\"{'AUC':<12} | {auc1:<10.4f} | {auc2:<10.4f}\")\n",
    "print(\"===============================================================\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

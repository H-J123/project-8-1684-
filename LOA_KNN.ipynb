{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b9d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "# ==============================================================\n",
    "# Lyrebird Optimization Algorithm (LOA)\n",
    "# for Feature Selection using KNN on KC2 Dataset\n",
    "# Comparison: With vs Without Feature Selection\n",
    "# Includes Convergence, Error, ROC, and AUC\n",
    "# ==============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# ==============================================================\n",
    "# Load Dataset\n",
    "# ==============================================================\n",
    "\n",
    "# âœ… Change this to your KC2 dataset location\n",
    "data = pd.read_csv(r\"/content/KC2_csv.csv\")\n",
    "print(\"âœ… Dataset Loaded Successfully!\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "y = data.iloc[:, -1]\n",
    "X = data.iloc[:, :-1]\n",
    "\n",
    "# Drop 'id' column if exists\n",
    "if 'id' in X.columns:\n",
    "    X.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# Normalize data\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Encode labels for metrics that require numerical values (like AUC) before splitting\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_encoded = le.fit_transform(y) # 'N' will be 0, 'Y' will be 1 (or vice versa depending on alphabetical alphabetical order)\n",
    "\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the encoded labels as well for consistency\n",
    "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "Dim = X_train.shape[1]\n",
    "\n",
    "# ==============================================================\n",
    "# âœ… Baseline: KNN without Feature Selection\n",
    "# ==============================================================\n",
    "\n",
    "knn_base = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_base.fit(X_train, y_train)\n",
    "pred_base = knn_base.predict(X_test)\n",
    "\n",
    "# For AUC, we need probability scores, and the target variable needs to be numerical (0/1)\n",
    "# Use the encoded y_test and get probability for the 'Y' class\n",
    "# Handle the case where 'Y' might not be in le.classes_ in the current split\n",
    "if 'Y' in le.classes_:\n",
    "    prob_base = knn_base.predict_proba(X_test)[:, le.transform(['Y'])[0]]\n",
    "else:\n",
    "    # Assuming 'Y' would be encoded as 1 if present.\n",
    "    # If 'Y' is not in test set, AUC might not be meaningful,\n",
    "    # but we avoid the error. Could also set prob_base to all 0s or 1s depending on context.\n",
    "    prob_base = np.zeros(len(X_test))\n",
    "\n",
    "\n",
    "# Compute Metrics using original y_test for classification reports\n",
    "acc_base = accuracy_score(y_test, pred_base)\n",
    "prec_base = precision_score(y_test, pred_base, pos_label='yes')\n",
    "rec_base = recall_score(y_test, pred_base, pos_label='yes')\n",
    "f1_base = f1_score(y_test, pred_base, pos_label='yes')\n",
    "\n",
    "# Use encoded y_test for AUC calculation\n",
    "# Handle the case where y_test_encoded might be all one class\n",
    "if len(np.unique(y_test_encoded)) > 1:\n",
    "  auc_base = roc_auc_score(y_test_encoded, prob_base)\n",
    "else:\n",
    "  # AUC is not defined for single-class datasets\n",
    "  auc_base = np.nan\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“Š Baseline KNN (All Features):\")\n",
    "print(f\"Accuracy : {acc_base:.4f}\")\n",
    "print(f\"Precision: {prec_base:.4f}\")\n",
    "print(f\"Recall   : {rec_base:.4f}\")\n",
    "print(f\"F1 Score : {f1_base:.4f}\")\n",
    "print(f\"AUC      : {auc_base:.4f}\")\n",
    "\n",
    "# ==============================================================\n",
    "# ðŸª¶ Lyrebird Optimization Algorithm (LOA)\n",
    "# ==============================================================\n",
    "\n",
    "def fitness_function(features):\n",
    "    \"\"\"Fitness based on KNN classification error\"\"\"\n",
    "    selected = np.where(features == 1)[0]\n",
    "    if len(selected) == 0:\n",
    "        return 1.0  # worst case if no feature selected\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    # Use encoded labels for training and testing within the fitness function\n",
    "    knn.fit(X_train_encoded.iloc[:, selected], y_train_encoded)\n",
    "    pred = knn.predict(X_test_encoded.iloc[:, selected])\n",
    "    # Calculate accuracy using encoded labels for the fitness function\n",
    "    acc = np.mean(pred == y_test_encoded)\n",
    "    return 1 - acc  # minimize classification error\n",
    "\n",
    "def LOA_feature_selection(Dim, MaxIter=150, N=30):\n",
    "    \"\"\"Lyrebird Optimization Algorithm for Feature Selection\"\"\"\n",
    "    # Initialize population\n",
    "    X_pop = np.random.randint(0, 2, (N, Dim))\n",
    "    Fitness = np.zeros(N)\n",
    "\n",
    "    # Parameters\n",
    "    alpha, beta, gamma = 0.5, 0.8, 0.9\n",
    "\n",
    "    # Initialize best\n",
    "    Best_FF = np.inf\n",
    "    Best_P = np.zeros(Dim)\n",
    "\n",
    "    # Evaluate initial population\n",
    "    for i in range(N):\n",
    "        Fitness[i] = fitness_function(X_pop[i])\n",
    "        if Fitness[i] < Best_FF:\n",
    "            Best_FF = Fitness[i]\n",
    "            Best_P = X_pop[i].copy()\n",
    "\n",
    "    Conv_curve = np.zeros(MaxIter)\n",
    "    Avg_error_curve = np.zeros(MaxIter)\n",
    "\n",
    "    print(\"\\nðŸš€ LOA Optimization Started...\\n\")\n",
    "\n",
    "    for t in range(MaxIter):\n",
    "        errors = []\n",
    "        for i in range(N):\n",
    "            # Lyrebird position update\n",
    "            A = alpha * np.random.uniform(-1, 1, Dim)\n",
    "            B = beta * np.random.uniform(0, 1, Dim)\n",
    "            C = gamma * np.random.uniform(0, 1)\n",
    "\n",
    "            new_pos = X_pop[i] + A * (Best_P - B * X_pop[i]) + C * np.random.randn(Dim)\n",
    "            new_pos = 1 / (1 + np.exp(-new_pos))\n",
    "            new_pos = np.where(new_pos > 0.5, 1, 0)\n",
    "\n",
    "            new_fit = fitness_function(new_pos)\n",
    "            errors.append(new_fit)\n",
    "\n",
    "            # Greedy selection\n",
    "            if new_fit < Fitness[i]:\n",
    "                X_pop[i] = new_pos.copy()\n",
    "                Fitness[i] = new_fit\n",
    "\n",
    "            if new_fit < Best_FF:\n",
    "                Best_FF = new_fit\n",
    "                Best_P = new_pos.copy()\n",
    "\n",
    "        Conv_curve[t] = Best_FF\n",
    "        Avg_error_curve[t] = np.mean(errors)\n",
    "\n",
    "        if t % 20 == 0 or t == MaxIter - 1:\n",
    "            print(f\"Iteration {t+1}/{MaxIter} -> Best Fitness: {Best_FF:.4f}\")\n",
    "\n",
    "    print(\"\\nâœ… LOA Optimization Completed!\")\n",
    "    return Best_P, Best_FF, Conv_curve, Avg_error_curve\n",
    "\n",
    "# ==============================================================\n",
    "# Run LOA for Feature Selection\n",
    "# ==============================================================\n",
    "\n",
    "Best_features, Best_error, Conv_curve, Avg_error_curve = LOA_feature_selection(Dim=Dim, MaxIter=150, N=30)\n",
    "selected_idx = np.where(Best_features == 1)[0]\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Selected {len(selected_idx)} features out of {Dim}:\")\n",
    "print(list(X_train.columns[selected_idx]))\n",
    "\n",
    "# ==============================================================\n",
    "# Final KNN with LOA Selected Features\n",
    "# ==============================================================\n",
    "\n",
    "knn_loa = KNeighborsClassifier(n_neighbors=3)\n",
    "# Train with original labels for classification metrics\n",
    "knn_loa.fit(X_train.iloc[:, selected_idx], y_train)\n",
    "pred_loa = knn_loa.predict(X_test.iloc[:, selected_idx])\n",
    "\n",
    "# For AUC with LOA, use the encoded y_test and get probability for the 'Y' class\n",
    "# Handle the case where 'Y' might not be in le.classes_ in the current split\n",
    "if 'Y' in le.classes_:\n",
    "  prob_loa = knn_loa.predict_proba(X_test.iloc[:, selected_idx])[:, le.transform(['Y'])[0]]\n",
    "else:\n",
    "  # Assuming 'Y' would be encoded as 1 if present.\n",
    "  # If 'Y' is not in test set, AUC might not be meaningful,\n",
    "  # but we avoid the error. Could also set prob_loa to all 0s or 1s depending on context.\n",
    "  prob_loa = np.zeros(len(X_test))\n",
    "\n",
    "\n",
    "# Metrics using original y_test for classification reports\n",
    "acc_loa = accuracy_score(y_test, pred_loa)\n",
    "prec_loa = precision_score(y_test, pred_loa, pos_label='yes')\n",
    "rec_loa = recall_score(y_test, pred_loa, pos_label='yes')\n",
    "f1_loa = f1_score(y_test, pred_loa, pos_label='yes')\n",
    "\n",
    "# Use encoded y_test for AUC calculation\n",
    "# Handle the case where y_test_encoded might be all one class\n",
    "if len(np.unique(y_test_encoded)) > 1:\n",
    "  auc_loa = roc_auc_score(y_test_encoded, prob_loa)\n",
    "else:\n",
    "  # AUC is not defined for single-class datasets\n",
    "  auc_loa = np.nan\n",
    "\n",
    "\n",
    "print(\"\\nðŸ“Š KNN + LOA Feature Selection:\")\n",
    "print(f\"Accuracy : {acc_loa:.4f}\")\n",
    "print(f\"Precision: {prec_loa:.4f}\")\n",
    "print(f\"Recall   : {rec_loa:.4f}\")\n",
    "print(f\"F1 Score : {f1_loa:.4f}\")\n",
    "print(f\"AUC      : {auc_loa:.4f}\")\n",
    "\n",
    "# ==============================================================\n",
    "# Comparison Table\n",
    "# ==============================================================\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    \"Model\": [\"KNN (All Features)\", \"KNN + LOA (Selected Features)\"],\n",
    "    \"Accuracy\": [acc_base, acc_loa],\n",
    "    \"Precision\": [prec_base, prec_loa],\n",
    "    \"Recall\": [rec_base, rec_loa],\n",
    "    \"F1-Score\": [f1_base, f1_loa],\n",
    "    \"AUC\": [auc_base, auc_loa]\n",
    "})\n",
    "print(\"\\nðŸ“ˆ Comparison of KNN With & Without LOA:\\n\")\n",
    "print(results.to_string(index=False))\n",
    "\n",
    "# ==============================================================\n",
    "# Visualization\n",
    "# ==============================================================\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Convergence Plot\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(Conv_curve, 'b-', linewidth=2)\n",
    "plt.title(\"Convergence Curve (LOA)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Fitness (Error)\")\n",
    "plt.grid(True)\n",
    "\n",
    "# Average Error Plot\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(Avg_error_curve, 'r-', linewidth=2)\n",
    "plt.title(\"Average Error per Iteration (LOA)\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Average Error\")\n",
    "plt.grid(True)\n",
    "\n",
    "# ROC Curves\n",
    "# Ensure y_test_encoded has more than one class before plotting ROC\n",
    "if len(np.unique(y_test_encoded)) > 1:\n",
    "  fpr_base, tpr_base, _ = roc_curve(y_test_encoded, prob_base)\n",
    "  fpr_loa, tpr_loa, _ = roc_curve(y_test_encoded, prob_loa)\n",
    "\n",
    "  plt.subplot(1, 3, 3)\n",
    "  plt.plot(fpr_base, tpr_base, 'b-', label=f'Baseline KNN (AUC={auc_base:.4f})')\n",
    "  plt.plot(fpr_loa, tpr_loa, 'g-', label=f'KNN + LOA (AUC={auc_loa:.4f})')\n",
    "  plt.plot([0, 1], [0, 1], 'k--')\n",
    "  plt.title(\"ROC Comparison\")\n",
    "  plt.xlabel(\"False Positive Rate\")\n",
    "  plt.ylabel(\"True Positive Rate\")\n",
    "  plt.legend()\n",
    "  plt.grid(True)\n",
    "else:\n",
    "  plt.subplot(1, 3, 3)\n",
    "  plt.text(0.5, 0.5, \"ROC Curve not available\\n(Single class in test set)\",\n",
    "           horizontalalignment='center', verticalalignment='center')\n",
    "  plt.title(\"ROC Comparison\")\n",
    "  plt.xlabel(\"False Positive Rate\")\n",
    "  plt.ylabel(\"True Positive Rate\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6357e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# SVM with and without Feature Selection using LOA\n",
    "# ==========================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, classification_report\n",
    "\n",
    "# -------------------------------\n",
    "# Load dataset\n",
    "# -------------------------------\n",
    "data = pd.read_csv(r\"/content/KC2_csv.csv\")  # Replace with your dataset path\n",
    "X = data.iloc[:, :-1].values\n",
    "y = data.iloc[:, -1].values\n",
    "\n",
    "# -------------------------------\n",
    "# Train-test split\n",
    "# -------------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ==========================================\n",
    "# Lyrebird Optimization Algorithm (LOA) for Feature Selection\n",
    "# ==========================================\n",
    "def LOA_feature_selection(X, y, num_agents=10, max_iter=30):\n",
    "    n_features = X.shape[1]\n",
    "    positions = np.random.randint(0, 2, (num_agents, n_features))\n",
    "    best_agent = None\n",
    "    best_fitness = -np.inf\n",
    "    fitness_curve = []\n",
    "\n",
    "    def fitness(agent):\n",
    "        if np.sum(agent) == 0:\n",
    "            return 0\n",
    "        selected = np.where(agent == 1)[0]\n",
    "        X_sel = X[:, selected]\n",
    "        X_train_fs, X_test_fs, y_train_fs, y_test_fs = train_test_split(X_sel, y, test_size=0.2)\n",
    "        model = SVC(kernel='rbf', probability=True)\n",
    "        model.fit(X_train_fs, y_train_fs)\n",
    "        y_pred = model.predict(X_test_fs)\n",
    "        return accuracy_score(y_test_fs, y_pred)\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        for i in range(num_agents):\n",
    "            fit = fitness(positions[i])\n",
    "            if fit > best_fitness:\n",
    "                best_fitness = fit\n",
    "                best_agent = positions[i].copy()\n",
    "\n",
    "        # Update positions (LOA mechanism)\n",
    "        for i in range(num_agents):\n",
    "            for j in range(n_features):\n",
    "                if np.random.rand() < 0.3:\n",
    "                    positions[i][j] = 1 - positions[i][j]  # flip bit\n",
    "\n",
    "        fitness_curve.append(best_fitness)\n",
    "        print(f\"Iteration {t+1}/{max_iter} | Best Fitness: {best_fitness:.4f}\")\n",
    "\n",
    "    plt.plot(fitness_curve)\n",
    "    plt.title(\"Lyrebird Optimization - Fitness Curve\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    selected_features = np.where(best_agent == 1)[0]\n",
    "    print(\"Selected features:\", selected_features)\n",
    "    return selected_features\n",
    "\n",
    "# ==========================================\n",
    "# 1️⃣ SVM with Feature Selection (LOA)\n",
    "# ==========================================\n",
    "selected_features = LOA_feature_selection(X_train, y_train)\n",
    "X_train_fs = X_train[:, selected_features]\n",
    "X_test_fs = X_test[:, selected_features]\n",
    "\n",
    "svm_fs = SVC(kernel='rbf', probability=True)\n",
    "svm_fs.fit(X_train_fs, y_train)\n",
    "y_pred_fs = svm_fs.predict(X_test_fs)\n",
    "y_prob_fs = svm_fs.predict_proba(X_test_fs)[:, 1]\n",
    "\n",
    "print(\"\\n--- SVM WITH FEATURE SELECTION ---\")\n",
    "print(classification_report(y_test, y_pred_fs))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_fs))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob_fs))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_fs, pos_label='yes')\n",
    "plt.plot(fpr, tpr, label='SVM with Feature Selection (AUC = %.3f)' % roc_auc_score(y_test, y_prob_fs))\n",
    "plt.title(\"ROC Curve - With Feature Selection\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ==========================================\n",
    "# 2️⃣ SVM without Feature Selection\n",
    "# ==========================================\n",
    "svm_nofs = SVC(kernel='rbf', probability=True)\n",
    "svm_nofs.fit(X_train, y_train)\n",
    "y_pred_nofs = svm_nofs.predict(X_test)\n",
    "y_prob_nofs = svm_nofs.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n--- SVM WITHOUT FEATURE SELECTION ---\")\n",
    "print(classification_report(y_test, y_pred_nofs))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nofs))\n",
    "print(\"AUC:\", roc_auc_score(y_test, y_prob_nofs))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, y_prob_nofs, pos_label='yes')\n",
    "plt.plot(fpr, tpr, label='SVM without Feature Selection (AUC = %.3f)' % roc_auc_score(y_test, y_prob_nofs))\n",
    "plt.title(\"ROC Curve - Without Feature Selection\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
